<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Lincoln Mullen" />

<meta name="date" content="2015-10-22" />

<title>Introduction to the textreuse package</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0A%7D%0Apre%20%7B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>



<div id="header">
<h1 class="title">Introduction to the textreuse package</h1>
<h4 class="author"><em>Lincoln Mullen</em></h4>
<h4 class="date"><em>2015-10-22</em></h4>
</div>


<p>The textreuse package provides classes and functions to detect document similarity and text reuse in text corpora. This introductory vignette provides details on the <code>TextReuseTextDocument</code> and <code>TextReuseCorpus</code> classes, as well as functions for tokenizing, hashing, and measuring similarity. See the pairwise or minhash/LSH vignettes for details on solving text similarity problems.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">vignette</span>(<span class="st">&quot;introduction&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;textreuse&quot;</span>)
<span class="kw">vignette</span>(<span class="st">&quot;pairwise&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;textreuse&quot;</span>)
<span class="kw">vignette</span>(<span class="st">&quot;minhash&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;textreuse&quot;</span>)</code></pre></div>
<p>For these vignette we will use a small corpus of eight documents published by the <a href="https://en.wikipedia.org/wiki/American_Tract_Society">American Tract Society</a> and available from the Internet Archive. The <a href="http://lincolnmullen.com/blog/corpus-of-american-tract-society-publications/">full corpus</a> is also available to be downloaded if you wish to test the package.</p>
<div id="textreuse-classes" class="section level2">
<h2>TextReuse classes</h2>
<div id="textreusetextdocument" class="section level3">
<h3>TextReuseTextDocument</h3>
<p>The most basic class provided by this package is the <code>TextReuseTextDocument</code> class. This class contains the text of a document and its metadata. When the document is loaded, the text is also tokenized. (See the section on tokenizers below.) Those tokens are then hashed using a hash function. By default the hashes are retained and the tokens are discarded, since using only hashes results in a significant memory savings.</p>
<p>Here we load a file into a <code>TextReuseTextDocument</code> and tokenize it into shingled n-grams, adding an option to retain the tokens.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(textreuse)
file &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;extdata/ats/remember00palm.txt&quot;</span>, 
                    <span class="dt">package =</span> <span class="st">&quot;textreuse&quot;</span>)
doc &lt;-<span class="st"> </span><span class="kw">TextReuseTextDocument</span>(<span class="dt">file =</span> file, <span class="dt">meta =</span> <span class="kw">list</span>(<span class="st">&quot;publisher&quot;</span> =<span class="st"> &quot;ATS&quot;</span>),
                             <span class="dt">tokenizer =</span> tokenize_ngrams, <span class="dt">n =</span> <span class="dv">5</span>,
                             <span class="dt">keep_tokens =</span> <span class="ot">TRUE</span>)
doc</code></pre></div>
<pre><code>## TextReuseTextDocument
## file : /Users/lmullen/Library/R/3.2/library/textreuse/extdata/ats/remember00palm.txt 
## hash_func : hash_string 
## id : remember00palm 
## publisher : ATS 
## tokenizer : tokenize_ngrams 
## content : Remember 
## By 
## Rat Palmer. 
## Boston: 
## 
## THE AMERICAN TRACT SOCI] 
## 
## Depositories, 28 Cornhill, Boston ; and 13 Biblb House, 
## Astor Place, New York. 
## Entered, according to Act of Congress, in the year 1865</code></pre>
<p>We can see details of the document with accessor functions. These are derived from the S3 virtual class <code>TextDocument</code> in the <a href="https://cran.r-project.org/package=NLP">NLP</a> package. Notice that an ID has been assigned to the document based on the filename (without the extension). The name of the tokenizer and hash functions are also saved in the metadata.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">meta</span>(doc)</code></pre></div>
<pre><code>## $file
## [1] &quot;/Users/lmullen/Library/R/3.2/library/textreuse/extdata/ats/remember00palm.txt&quot;
## 
## $hash_func
## [1] &quot;hash_string&quot;
## 
## $id
## [1] &quot;remember00palm&quot;
## 
## $publisher
## [1] &quot;ATS&quot;
## 
## $tokenizer
## [1] &quot;tokenize_ngrams&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">meta</span>(doc, <span class="st">&quot;id&quot;</span>)</code></pre></div>
<pre><code>## [1] &quot;remember00palm&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">meta</span>(doc, <span class="st">&quot;date&quot;</span>) &lt;-<span class="st"> </span><span class="dv">1865</span>
<span class="kw">head</span>(<span class="kw">tokens</span>(doc))</code></pre></div>
<pre><code>## [1] &quot;remember by rat palmer boston&quot;       
## [2] &quot;by rat palmer boston the&quot;            
## [3] &quot;rat palmer boston the american&quot;      
## [4] &quot;palmer boston the american tract&quot;    
## [5] &quot;boston the american tract soci&quot;      
## [6] &quot;the american tract soci depositories&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(<span class="kw">hashes</span>(doc))</code></pre></div>
<pre><code>## [1]   -96275747 -1721204321   707361410  -626087009  -532862870   141807655</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">wordcount</span>(doc)</code></pre></div>
<pre><code>## [1] 11399</code></pre>
<p>The <code>tokens()</code> and <code>hashes()</code> function return the tokens and hashes associated with the document. The <code>meta()</code> function returns a named list of all the metadata fields. If that function is called with a specific ID, as in <code>meta(doc, &quot;myfield&quot;)</code>, then the value for only that field is returned. You can also assign to the metadata as a whole or a specific field, as in the example above.</p>
<p>In addition the <code>content()</code> function provides the unprocessed text of the document.</p>
<p>The assumption is that is that you want to tokenize and hash the tokens from the start. If, however, you wish to do any of those steps yourself, you can load a document with <code>tokenizer = NULL</code>, then use <code>tokenize()</code> or <code>rehash()</code> to recompute the tokens and hashes.</p>
</div>
<div id="textreusecorpus" class="section level3">
<h3>TextReuseCorpus</h3>
<p>The class <code>TextReuseCorpus</code> provides a list of <code>TextReuseTextDocuments</code>. It derives from the S3 virtual class <code>Corpus</code> in the <a href="https://cran.r-project.org/package=tm">tm</a> package. It can be created from a directory of files (or by providing a vector of paths to files).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dir &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;extdata/ats&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;textreuse&quot;</span>)
corpus &lt;-<span class="st"> </span><span class="kw">TextReuseCorpus</span>(<span class="dt">dir =</span> dir, <span class="dt">tokenizer =</span> tokenize_ngrams, <span class="dt">n =</span> <span class="dv">5</span>)</code></pre></div>
<pre><code>## Loading, tokenizing, and hashing 8 documents.</code></pre>
<pre><code>## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |========                                                         |  12%
  |                                                                       
  |================                                                 |  25%
  |                                                                       
  |========================                                         |  38%
  |                                                                       
  |================================                                 |  50%
  |                                                                       
  |=========================================                        |  62%
  |                                                                       
  |=================================================                |  75%
  |                                                                       
  |=========================================================        |  88%
  |                                                                       
  |=================================================================| 100%</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">corpus</code></pre></div>
<pre><code>## TextReuseCorpus
## Number of documents: 8 
## hash_func : hash_string 
## tokenizer : tokenize_ngrams</code></pre>
<p>The names of the items in a <code>TextReuseCorpus</code> are the IDs of the documents. You can use these IDs to subset the corpus or to retrieve specific documents.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">names</span>(corpus)</code></pre></div>
<pre><code>## [1] &quot;calltounconv00baxt&quot;        &quot;gospeltruth00whit&quot;        
## [3] &quot;lifeofrevrichard00baxt&quot;    &quot;memoirjamesbrai00ricegoog&quot;
## [5] &quot;practicalthought00nev&quot;     &quot;remember00palm&quot;           
## [7] &quot;remembermeorholy00palm&quot;    &quot;thoughtsonpopery00nevi&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">corpus[[<span class="st">&quot;remember00palm&quot;</span>]]</code></pre></div>
<pre><code>## TextReuseTextDocument
## file : /Users/lmullen/Library/R/3.2/library/textreuse/extdata/ats/remember00palm.txt 
## hash_func : hash_string 
## id : remember00palm 
## tokenizer : tokenize_ngrams 
## content : Remember 
## By 
## Rat Palmer. 
## Boston: 
## 
## THE AMERICAN TRACT SOCI] 
## 
## Depositories, 28 Cornhill, Boston ; and 13 Biblb House, 
## Astor Place, New York. 
## Entered, according to Act of Congress, in the year 1865</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">corpus[<span class="kw">c</span>(<span class="st">&quot;calltounconv00baxt&quot;</span>, <span class="st">&quot;lifeofrevrichard00baxt&quot;</span>)]</code></pre></div>
<pre><code>## TextReuseCorpus
## Number of documents: 2 
## hash_func : hash_string 
## tokenizer : tokenize_ngrams</code></pre>
<p>Accessor functions such as <code>meta()</code>, <code>tokens()</code>, <code>hashes()</code>, and <code>wordcount()</code> have methods that work on corpora.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">wordcount</span>(corpus)</code></pre></div>
<pre><code>##        calltounconv00baxt         gospeltruth00whit 
##                    134616                     16593 
##    lifeofrevrichard00baxt memoirjamesbrai00ricegoog 
##                     44283                    131939 
##     practicalthought00nev            remember00palm 
##                    124544                     11399 
##    remembermeorholy00palm    thoughtsonpopery00nevi 
##                     11532                     64758</code></pre>
<p>Note that when creating a corpus, very short or empty documents will be skipped with a warning. A document must have enough words to create at least two n-grams. For example, if five-grams are desired, then the document must have at least six words.</p>
</div>
</div>
<div id="tokenizers" class="section level2">
<h2>Tokenizers</h2>
<p>One of the steps that is performed when loading a <code>TextReuseTextDocument</code>, either individual or in a corpus, is tokenization. Tokenization breaks up a text into pieces, often overlapping. These pieces are the features which are compared when measuring document similarity.</p>
<p>The textreuse package provides a number of tokenizers.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">text &lt;-<span class="st"> &quot;How many roads must a man walk down</span><span class="ch">\n</span><span class="st">Before you'll call him a man?&quot;</span>

<span class="kw">tokenize_words</span>(text)</code></pre></div>
<pre><code>##  [1] &quot;how&quot;    &quot;many&quot;   &quot;roads&quot;  &quot;must&quot;   &quot;a&quot;      &quot;man&quot;    &quot;walk&quot;  
##  [8] &quot;down&quot;   &quot;before&quot; &quot;you'll&quot; &quot;call&quot;   &quot;him&quot;    &quot;a&quot;      &quot;man&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tokenize_sentences</span>(text)</code></pre></div>
<pre><code>## [1] &quot;how many roads must a man walk down&quot;
## [2] &quot;before you ll call him a man&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tokenize_ngrams</span>(text, <span class="dt">n =</span> <span class="dv">3</span>)</code></pre></div>
<pre><code>##  [1] &quot;how many roads&quot;     &quot;many roads must&quot;    &quot;roads must a&quot;      
##  [4] &quot;must a man&quot;         &quot;a man walk&quot;         &quot;man walk down&quot;     
##  [7] &quot;walk down before&quot;   &quot;down before you'll&quot; &quot;before you'll call&quot;
## [10] &quot;you'll call him&quot;    &quot;call him a&quot;         &quot;him a man&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tokenize_skip_ngrams</span>(text, <span class="dt">n =</span> <span class="dv">3</span>, <span class="dt">k =</span> <span class="dv">2</span>)</code></pre></div>
<pre><code>##  [1] &quot;how must walk&quot;      &quot;many a down&quot;        &quot;roads man before&quot;  
##  [4] &quot;must walk you'll&quot;   &quot;a down call&quot;        &quot;man before him&quot;    
##  [7] &quot;walk you'll a&quot;      &quot;down call man&quot;      &quot;how roads a&quot;       
## [10] &quot;many must man&quot;      &quot;roads a walk&quot;       &quot;must man down&quot;     
## [13] &quot;a walk before&quot;      &quot;man down you'll&quot;    &quot;walk before call&quot;  
## [16] &quot;down you'll him&quot;    &quot;before call a&quot;      &quot;you'll him man&quot;    
## [19] &quot;how many roads&quot;     &quot;many roads must&quot;    &quot;roads must a&quot;      
## [22] &quot;must a man&quot;         &quot;a man walk&quot;         &quot;man walk down&quot;     
## [25] &quot;walk down before&quot;   &quot;down before you'll&quot; &quot;before you'll call&quot;
## [28] &quot;you'll call him&quot;    &quot;call him a&quot;         &quot;him a man&quot;</code></pre>
<p>You can write your own tokenizers or use tokenizers from other packages. They should accept a character vector as their first argument.</p>
<p>As an example, we will write a tokenizer function using the  package which splits a text on new lines, perhaps useful for poetry. Notice that the function takes a single string and returns a character vector with one element for each line. (A more robust tokenizer might strip blank lines and punction, include an option for lowercasing the text, and check for the validity of arguments.)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">poem &lt;-<span class="st"> &quot;Roses are red</span><span class="ch">\n</span><span class="st">Violets are blue</span><span class="ch">\n</span><span class="st">I like using R</span><span class="ch">\n</span><span class="st">And you should too&quot;</span>
<span class="kw">cat</span>(poem)</code></pre></div>
<pre><code>## Roses are red
## Violets are blue
## I like using R
## And you should too</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tokenize_lines &lt;-<span class="st"> </span>function(string) {
  stringr::<span class="kw">str_split</span>(string, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">+&quot;</span>)[[<span class="dv">1</span>]]
}

<span class="kw">tokenize_lines</span>(poem)</code></pre></div>
<pre><code>## [1] &quot;Roses are red&quot;      &quot;Violets are blue&quot;   &quot;I like using R&quot;    
## [4] &quot;And you should too&quot;</code></pre>
</div>
<div id="hash-functions" class="section level2">
<h2>Hash functions</h2>
<p>This package provides one function to hash tokens to integers, <code>hash_string()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hash_string</span>(<span class="kw">tokenize_words</span>(text))</code></pre></div>
<pre><code>##  [1]   -78131211  -909288800  -647481819  -909500956 -1640531430
##  [6]   -78235283  -904724921  -889252160   317438038   937035765
## [11]  -890718890   -78132909 -1640531430   -78235283</code></pre>
<p>You can write your own hash functions, or use those provided by the <a href="https://cran.r-project.org/package=digest">digest</a> package.</p>
</div>
<div id="comparison-functions" class="section level2">
<h2>Comparison functions</h2>
<p>This package provides a number of comparison functions for measuring similarity. These functions take either a set (in which each token is counted one time) or a bag (in which each token is counted as many times as it appears) and compares it to another set or bag.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">a &lt;-<span class="st"> </span><span class="kw">tokenize_words</span>(<span class="kw">paste</span>(<span class="st">&quot;How does it feel, how does it feel?&quot;</span>,
                          <span class="st">&quot;To be without a home&quot;</span>,
                          <span class="st">&quot;Like a complete unknown, like a rolling stone&quot;</span>))
b &lt;-<span class="st"> </span><span class="kw">tokenize_words</span>(<span class="kw">paste</span>(<span class="st">&quot;How does it feel, how does it feel?&quot;</span>,
                          <span class="st">&quot;To be on your own, with no direction home&quot;</span>,
                          <span class="st">&quot;A complete unknown, like a rolling stone&quot;</span>))

<span class="kw">jaccard_similarity</span>(a, b)</code></pre></div>
<pre><code>## [1] 0.65</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">jaccard_dissimilarity</span>(a, b)</code></pre></div>
<pre><code>## [1] 0.35</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">jaccard_bag_similarity</span>(a, b)</code></pre></div>
<pre><code>## [1] 0.4</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ratio_of_matches</span>(a, b)</code></pre></div>
<pre><code>## [1] 0.75</code></pre>
<p>See the documentation for <code>?similarity-functions</code> for details on what is measured with these functions.</p>
<p>You can write your own similarity functions, which should accept two sets or bags, <code>a</code> and <code>b</code>, should work on both character and numeric vectors, since they are used with either tokens or hashes of tokens, and should return a single numeric score for the comparison. You will need to implement a method for the <code>TextReuseTextDocument</code> class.</p>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
