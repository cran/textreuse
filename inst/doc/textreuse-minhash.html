<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Lincoln Mullen" />

<meta name="date" content="2020-05-15" />

<title>Minhash and locality-sensitive hashing</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Minhash and locality-sensitive hashing</h1>
<h4 class="author">Lincoln Mullen</h4>
<h4 class="date">2020-05-15</h4>



<p>Performing pairwise comparisons in a corpus is time-consuming because the number of comparisons grows geometrically with the size of the corpus. Most of those comparisons, furthermore, are unnecessary because they do not result in matches. The combination of minhash and locality-sensitive hashing (LSH) seeks to solve these problems. They make it possible to compute possible matches only once for each document, so that the cost of computation grows linearly rather than exponentially. This vignette explains how to use the minhash and locality-sensitive hashing functions in this package. For an explanation of why they work, see Jure Leskovec, Anand Rajaraman, and Jeff Ullman, <em><a href="http://www.mmds.org/#book">Mining of Massive Datasets</a></em> (Cambridge University Press, 2011), ch.Â 3. (This <a href="http://matthewcasperson.blogspot.com/2013/11/minhash-for-dummies.html">blog post</a> is a more succinct explanation.)</p>
<p>We begin by creating a minhash function. A minhash function converts tokenized text into a set of hash integers, then selects the minimum value. This is the equivalent of randomly selecting a token. The function then does the same thing repeatedly with different hashing functions, in effect selecting <code>n</code> random shingles. The additional hashing functions come from a bitwise XOR with random integers. That is why the <code>minhash_generator()</code> accepts a seed, so that we can re-create the same minhash function again. In other words, a minhash function converts a set of tokens of any length into <code>n</code> randomly selected and hashed tokens.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="kw">library</span>(textreuse)</span>
<span id="cb1-2"><a href="#cb1-2"></a>minhash &lt;-<span class="st"> </span><span class="kw">minhash_generator</span>(<span class="dt">n =</span> <span class="dv">240</span>, <span class="dt">seed =</span> <span class="dv">3552</span>)</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="kw">head</span>(<span class="kw">minhash</span>(<span class="kw">c</span>(<span class="st">&quot;turn tokens into&quot;</span>, <span class="st">&quot;tokens into hashes&quot;</span>, <span class="st">&quot;into hashes fast&quot;</span>)))</span></code></pre></div>
<pre><code>## [1] -1067902788  -349477925 -1306490031  -926753052 -1222296305 -1443723653</code></pre>
<p>Now when we load our corpus, we will tokenize our texts as usual, but we will use our generated <code>minhash()</code> function to compute the hashes. We specify that we want to create a minhash signature by passing our minhash function to the <code>minhash_func =</code> parameter.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a>dir &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;extdata/ats&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;textreuse&quot;</span>)</span>
<span id="cb3-2"><a href="#cb3-2"></a>corpus &lt;-<span class="st"> </span><span class="kw">TextReuseCorpus</span>(<span class="dt">dir =</span> dir, <span class="dt">tokenizer =</span> tokenize_ngrams, <span class="dt">n =</span> <span class="dv">5</span>,</span>
<span id="cb3-3"><a href="#cb3-3"></a>                          <span class="dt">minhash_func =</span> minhash, <span class="dt">keep_tokens =</span> <span class="ot">TRUE</span>,</span>
<span id="cb3-4"><a href="#cb3-4"></a>                          <span class="dt">progress =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<p>We can verify that we have minhashes in our corpus:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1"></a><span class="kw">head</span>(<span class="kw">minhashes</span>(corpus[[<span class="dv">1</span>]]))</span></code></pre></div>
<pre><code>## [1] -2147421589 -2147475954 -2147470602 -2147373716 -2147464099 -2147477501</code></pre>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1"></a><span class="kw">length</span>(<span class="kw">minhashes</span>(corpus[[<span class="dv">1</span>]]))</span></code></pre></div>
<pre><code>## [1] 240</code></pre>
<p>Now all our documents are represented by <code>n = 240</code> randomly selected and hashed shingles. Comparing those shingles should be the equivalent of finding the Jaccard similarity of the two documents. However, we still have the problem of pairwise comparison.</p>
<p>The locality-sensitive hashing algorithm, provided in this package by the <code>lsh()</code> function, solves this problem. LSH breaks the minhashes into a series of bands comprised of rows. For example, 200 minhashes might broken into 50 bands of 4 rows each. Each band is hashed to a bucket. If two documents have the exact same minhashes in a band, they will be hashed to the same bucket, and so will be considered candidate pairs. Each pair of documents has as many chances to be considered a candidate as their are bands, and the fewer rows there are in each band, the more likely it is that each document will match another.</p>
<p>How likely is it, then, that we will detect a match? The probability of a match depends on the Jaccard similarity of a pair of documents. The more similar two documents are, the more likely they are to be considered candidates, which is what we want. The probability of a match is an S-curve (see Leskovec, Rajaraman, and Ullman), so there is a threshold Jaccard similarity above which documents are likely to be a match. We can calculate the likely threshold based on the number of minhashes and bands that we are using.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1"></a><span class="kw">lsh_threshold</span>(<span class="dt">h =</span> <span class="dv">200</span>, <span class="dt">b =</span> <span class="dv">50</span>)</span></code></pre></div>
<pre><code>## [1] 0.3760603</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a><span class="kw">lsh_threshold</span>(<span class="dt">h =</span> <span class="dv">240</span>, <span class="dt">b =</span> <span class="dv">80</span>)</span></code></pre></div>
<pre><code>## [1] 0.2320794</code></pre>
<p>Using 240 minhashes and 80 bands, we will likely detect documents with an actual Jaccard similarity of above 0.232. We can also estimate the probability that a pair of documents with a Jaccard similarity <code>s</code> will be marked as potential matches.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1"></a><span class="kw">lsh_probability</span>(<span class="dt">h =</span> <span class="dv">240</span>, <span class="dt">b =</span> <span class="dv">80</span>, <span class="dt">s =</span> <span class="fl">0.25</span>)</span></code></pre></div>
<pre><code>## [1] 0.7163087</code></pre>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1"></a><span class="kw">lsh_probability</span>(<span class="dt">h =</span> <span class="dv">240</span>, <span class="dt">b =</span>  <span class="dv">80</span>, <span class="dt">s =</span> <span class="fl">0.75</span>)</span></code></pre></div>
<pre><code>## [1] 1</code></pre>
<p>These numbers seem reasonable for our purposes, so we will set the number of minhashes at 240 and the number of bands at 80.</p>
<p>Now we can use the <code>lsh()</code> function to calculate the locality-sensitive hashes for our documents.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1"></a>buckets &lt;-<span class="st"> </span><span class="kw">lsh</span>(corpus, <span class="dt">bands =</span> <span class="dv">80</span>, <span class="dt">progress =</span> <span class="ot">FALSE</span>)</span>
<span id="cb16-2"><a href="#cb16-2"></a>buckets</span></code></pre></div>
<pre><code>## # A tibble: 640 x 2
##    doc                buckets                         
##    &lt;chr&gt;              &lt;chr&gt;                           
##  1 calltounconv00baxt 94857bb94afab43e61fbdb7bc720d879
##  2 calltounconv00baxt a3b655b3a4da5b2615ad14b8b0a40c79
##  3 calltounconv00baxt 3a7dc2db81e921147904e776e51682c1
##  4 calltounconv00baxt d25c0330cfb7c5351c641b6fd66e9d9e
##  5 calltounconv00baxt 17d4e4e622ed0e22ada62b3021710f5c
##  6 calltounconv00baxt 6541b20eeb120392f7aa84e4efe000f9
##  7 calltounconv00baxt 5662312d987a1e8cfb39a8768e6373fa
##  8 calltounconv00baxt 36409960b62875444d6bc8b140d07a9d
##  9 calltounconv00baxt 239d06f6ef65a388dc2e3fa15a83fe3b
## 10 calltounconv00baxt 5fa1e53764fce4042dc15e56a1323b54
## # â¦ with 630 more rows</code></pre>
<p>Note that using the LSH method only requires us to calculate the signatures (or buckets) for each document one time. This implies that we can take several data frames of LSH signatures and bind their rows together (e.g., with <code>dplyr::bind_rows()</code>). This permits us to compute the signatures for only part of a corpus at a time, or to continue to add to the corpus. Note, however, that you <strong>must</strong> use the same minhash function, generating the same number of minhashes and using the same seed and you <strong>must</strong> use the same number of bands in order to get valid results.</p>
<p>We can extract the potential matches from the cache using <code>lsh_query()</code> or <code>lsh_candidates()</code>. The first function returns matches for only one document, specified by its ID; the second functions returns all potential pairs of matches.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1"></a>baxter_matches &lt;-<span class="st"> </span><span class="kw">lsh_query</span>(buckets, <span class="st">&quot;calltounconv00baxt&quot;</span>)</span>
<span id="cb18-2"><a href="#cb18-2"></a>baxter_matches</span></code></pre></div>
<pre><code>## # A tibble: 1 x 2
##   a                  b                     
##   &lt;chr&gt;              &lt;chr&gt;                 
## 1 calltounconv00baxt lifeofrevrichard00baxt</code></pre>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1"></a>candidates &lt;-<span class="st"> </span><span class="kw">lsh_candidates</span>(buckets)</span>
<span id="cb20-2"><a href="#cb20-2"></a>candidates</span></code></pre></div>
<pre><code>## # A tibble: 3 x 3
##   a                     b                      score
##   &lt;chr&gt;                 &lt;chr&gt;                  &lt;dbl&gt;
## 1 calltounconv00baxt    lifeofrevrichard00baxt    NA
## 2 practicalthought00nev thoughtsonpopery00nevi    NA
## 3 remember00palm        remembermeorholy00palm    NA</code></pre>
<p>Notice that LSH has identified the same three pairs of documents as potential matches that we found with pairwise comparisons, but did so much faster. But we do not have similarity scores; we only know that these documents are likely to have Jaccard similarity scores above the 0.232 threshold.</p>
<p>Now we can use <code>lsh_compare()</code> to apply a similarity function to the candidate pairs of documents. Note that we only have to do 3 comparisons for all the candidates, instead of 28 pairs when comparing all 8 documents in the corpus pairwise.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1"></a><span class="kw">lsh_compare</span>(candidates, corpus, jaccard_similarity, <span class="dt">progress =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## # A tibble: 3 x 3
##   a                     b                      score
##   &lt;chr&gt;                 &lt;chr&gt;                  &lt;dbl&gt;
## 1 calltounconv00baxt    lifeofrevrichard00baxt 0.281
## 2 practicalthought00nev thoughtsonpopery00nevi 0.463
## 3 remember00palm        remembermeorholy00palm 0.701</code></pre>
<p>Note that these results are identical to what we calculated in the pairwise vignette, but required much less computation.</p>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
